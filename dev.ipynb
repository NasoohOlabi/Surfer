{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "# from Feed import Feed\n",
    "from typing import Iterator, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.80M/6.80M [00:14<00:00, 500kB/s]\n"
     ]
    }
   ],
   "source": [
    "from Surfer import GetBrowser,RedditFeed,Feed\n",
    "\n",
    "driver = GetBrowser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_script(fname):\n",
    "  script = ''\n",
    "  with open(f'./scripts/{fname}.js','r') as f:\n",
    "    script = f.read()\n",
    "  script = script.replace('\\n','')\n",
    "  def replacer(*args):\n",
    "    acc = script\n",
    "    for i,x in enumerate(args):\n",
    "      acc = acc.replace('#'+str(i),x)\n",
    "    return acc\n",
    "  return replacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"let x = [].slice.call(document.querySelectorAll(`div[data-scroller-first]`));x = x.filter(x => x.querySelector('i.icon-upvote'))[0] || x[0];x = x.querySelector(`h3`);console.log(x);return x\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_script('init_reddit')('h3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedditFeed(Feed):\n",
    "\tdef __init__(self, driver):\n",
    "\t\tsuper()\n",
    "\t\tself.name = 'Reddit Feed'\n",
    "\t\t# Store the WebDriver instance\n",
    "\t\tself.driver = driver\n",
    "\t\tself.driver.get('https://www.reddit.com/')\n",
    "\n",
    "\t\t# Find the div[data-scroller-first] element\n",
    "\t\tself.first_element = WebDriverWait(self.driver, 10).until(\n",
    "\t\t\tEC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-scroller-first]'))\n",
    "\t\t)\n",
    "\t\t# Select all div elements with the attribute 'data-scroller-first'\n",
    "\t\tdivs = driver.find_elements(By.CSS_SELECTOR,\"div[data-scroller-first]\")\n",
    "\n",
    "\t\t# Filter the div elements that have a child element 'i' with class 'icon-upvote'\n",
    "\t\tfiltered_divs = [div for div in divs if div.find_elements(By.CSS_SELECTOR,\"i.icon-upvote\")]\n",
    "\n",
    "\t\t# Perform actions on the filtered div elements\n",
    "\t\tfor filtered_div in filtered_divs:\n",
    "\t\t\t\t# Perform actions on the filtered div element\n",
    "\t\t\t\t# For example, you can retrieve text, click, or interact with the element as needed\n",
    "\t\t\t\tprint(filtered_div.text)\n",
    "\t\tself.the_first_element = divs[0]\n",
    "\t\tself.first_element = self.the_first_element\n",
    "\n",
    "\t\tprint(self.the_first_element)\n",
    "\n",
    "\tdef __iter__(self) -> Iterator[Any]:\n",
    "\t  # Check if there are no more siblings\n",
    "\t\tif not self.first_element:\n",
    "\t\t\traise StopIteration\n",
    "\n",
    "\t\t# Scroll the first element into view with random scroll position\n",
    "\t\tself.scroll_element_into_view(self.first_element, random.uniform(0.2, 0.8))\n",
    "\n",
    "\t\t# Get the parent element of the first_element\n",
    "\t\tparent_element = self.first_element.find_element(By.XPATH, '..')\n",
    "\n",
    "\t\t# Get all the child elements (siblings) of the parent_element\n",
    "\t\tsiblings = parent_element.find_elements(By.XPATH, '*')\n",
    "\n",
    "\t\t# Iterate over the siblings and yield their text\n",
    "\t\tfor sibling in siblings:\n",
    "\t\t\t# Scroll each sibling element into view with random scroll position\n",
    "\t\t\tself.scroll_element_into_view(sibling, random.uniform(0.2, 0.8))  # Add random scroll position between 0.2 and 0.8\n",
    "\t\t\tyield sibling.text\n",
    "\n",
    "\t\t# Set the first_element to None to mark the end of iteration\n",
    "\t\tself.first_element = None\n",
    "\n",
    "\tdef scroll_element_into_view(self, element, scroll_position=0.5):\n",
    "\t\t# Get the element's height\n",
    "\t\telement_height = element.size['height']\n",
    "\n",
    "\t\t# Calculate the target scroll position based on the element's height and the given scroll position\n",
    "\t\ttarget_scroll_position = element.location['y'] + element_height * scroll_position\n",
    "\n",
    "\t\t# Scroll the page to the target scroll position using JavaScript\n",
    "\t\tself.driver.execute_script(\"window.scrollTo(0, arguments[0]);\", target_scroll_position)\n",
    "\n",
    "\tdef close(self):\n",
    "\t\t# Close the WebDriver instance\n",
    "\t\tself.driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Reddit Feed'\n",
    "# Store the WebDriver instance\n",
    "driver = driver\n",
    "driver.get('https://www.reddit.com/')\n",
    "\n",
    "# Find the div[data-scroller-first] element\n",
    "first_element = WebDriverWait(driver, 10).until(\n",
    "\tEC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-scroller-first]'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can‚Äôt with the smugness‚Ä¶post has 10k comments and all of them supporting this like ‚Äúyass go baby mama‚Äù.\n"
     ]
    }
   ],
   "source": [
    "def run_script(name,verbose=False):\n",
    "\tdef script(*args):\n",
    "\t\tscript_string = get_script(name)(*args)\n",
    "\t\tif verbose:\n",
    "\t\t\tprint('script_string: ',script_string)\n",
    "\t\treturn driver.execute_script(script_string)\n",
    "\treturn script\n",
    "x = run_script('init_reddit')('h3')\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12.9kr/facepalm‚Ä¢Posted byu/SyloriaRocius10 hours agoJoinI can‚Äôt with the smugness‚Ä¶post has 10k comments and all of them supporting this like ‚Äúyass go baby mama‚Äù. üá≤\\u200büáÆ\\u200büá∏\\u200büá®\\u200b\\n              \\n            \\n        .t3_12qbxb0._2FCtq-QzlfuN-SwVMUZMM3 {\\n          --postTitle-VisitedLinkColor: #edeeef;\\n          --postTitleLink-VisitedLinkColor: #6f7071;\\n          --postBodyLink-VisitedLinkColor: #6f7071;\\n        }\\n      12.9k4.9k commentssharesave'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_script('reddit next')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "for i in range(10):\n",
    "\tsleep(3)\n",
    "\trun_script('reddit scroll next',verbose=True)(\"0.5\",'0.5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
