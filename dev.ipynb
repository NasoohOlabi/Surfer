{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys\n",
        "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '../'))\n",
        "if parent_dir not in sys.path:\n",
        "    sys.path.insert(0, parent_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from itertools import islice\n",
        "import time\n",
        "from random import randint\n",
        "import random\n",
        "from icecream import ic\n",
        "from datetime import datetime\n",
        "import json\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\nasoo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Setting up Masked Stego\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Setting up Masked Stego Completed\n",
            "\n",
            "\n",
            "Setting up Typoceros\n",
            "\n",
            "('hi, how atre you?', '01001011111')\n",
            "\n",
            "Setting up Typoceros Completed\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from Surfer import GetBrowser,RedditFeed,Feed,ChatGPT,ChatGPTWebsite\n",
        "from Surfer.ScriptRunner import ScriptRunner\n",
        "from files import *\n",
        "from Stegasus import stegasus\n",
        "from Bot import *\n",
        "from Chatter import prompts\n",
        "from Surfer.util import uuid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<module 'Chatter.prompts' from 'c:\\\\Users\\\\nasoo\\\\Desktop\\\\Y5Project\\\\Port\\\\Chatter\\\\prompts.py'>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import importlib\n",
        "\n",
        "importlib.reload(prompts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "75 Bytes\n"
          ]
        }
      ],
      "source": [
        "bits_len = 200\n",
        "data = stegasus.random_bit_stream(bits_len)\n",
        "print(f'{bits_len // 8} Bytes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "cache = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('posts.json','r') as po:\n",
        "\tcache['posts'] = json.loads(po.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Encoder:\n",
        "\tdef __init__(self,data,dataLog,encodedChatLog,identity=False):\n",
        "\t\tself.data = data\n",
        "\t\tself.rem = data\n",
        "\t\tself.dataLog = dataLog\n",
        "\t\tself.encodedChatLog = encodedChatLog\n",
        "\t\tself.dataLog.append('')\n",
        "\t\tself.sending_pure_padding = False\n",
        "\t\tself.identity = identity\n",
        "\n",
        "\tdef done(self):\n",
        "\t\treturn self.sending_pure_padding \n",
        "\n",
        "\tdef __call__(self,text) -> str:\n",
        "\t\t# sending pure padding\n",
        "\t\tself.sending_pure_padding = len(self.rem) < 499\n",
        "\t\tif self.identity:\n",
        "\t\t\ta = text\n",
        "\t\t\tself.rem = self.rem[60:]\n",
        "\t\telse:\n",
        "\t\t\ta, self.rem = stegasus.StegasusEncode(text,self.rem)\n",
        "\t\tself.encodedChatLog.append(a)\n",
        "\t\tself.dataLog.append(self.data[len(self.dataLog[-1]):-len(self.rem)])\n",
        "\t\treturn a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import importlib\n",
        "# importlib.reload(prompts)\n",
        "\n",
        "# backup_post = [p for p in cache['posts'] if not (p['title'] is not None and p['title'] != \"\" and p['excerpt'] is not None and p['excerpt'] != \"\")][0]\n",
        "# a = prompts.inChatReplyPrompt(Message(Person('alice','nice',23,'female','Boston','alice@gmail.com'),'sup dog'),backup_post)\n",
        "# print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['posts']\n",
            "['posts']\n"
          ]
        }
      ],
      "source": [
        "print(list(cache.keys()))\n",
        "# del cache['data']\n",
        "# del cache['driver']\n",
        "# del cache['RedditFeed']\n",
        "# del cache['posts']\n",
        "# del cache['ChatGPTWebsite']\n",
        "# del cache['encodedChatLog']\n",
        "# del cache['chatLog']\n",
        "# del cache['promptLog']\n",
        "# del cache['dataLog']\n",
        "# del cache['aliceChat']\n",
        "# del cache['bobChat']\n",
        "print(list(cache.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from icecream import ic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tell(cache,dir_path):\n",
        "  with open(f'{dir_path}/cache.json','w') as f:\n",
        "    f.write(json.dumps({\n",
        "      'chatLog':cache['chatLog']\n",
        "      , 'encodedChatLog': cache['encodedChatLog']\n",
        "      , 'promptLog': cache['promptLog']\n",
        "      , 'dataLog': cache['dataLog']\n",
        "      , 'data': cache['data']\n",
        "      },cls=MessageEncoder,indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# define openChannelAndSend(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def openChannelAndSend(data:str\n",
        ", alice = Person('alice','nice',23,'female','Boston','alice@gmail.com')\n",
        ", bob = Person('bob','wick',29,'male','Boston','bob@gmail.com')\n",
        ", subreddit='unpopularopinion'\n",
        ", identity=False):\n",
        "\tdata += '1' + ('0' * 500)\n",
        "\tcache['data'] = data\n",
        "\tif 'driver' in cache:\n",
        "\t\tdriver = cache['driver']\n",
        "\telse:\n",
        "\t\tcache['driver'] = GetBrowser()\n",
        "\t\tdriver = cache['driver']\n",
        "\tdriver.implicitly_wait(2)\n",
        "\trf = RedditFeed(driver,skip=False,subreddit=subreddit,newWindow=False)\n",
        "\tposts = []\n",
        "\tif 'posts' in cache:\n",
        "\t\tposts = cache['posts']\n",
        "\telse:\n",
        "\t\tfor x in islice(rf,15):\n",
        "\t\t\tposts.append(x)\n",
        "\t\t\ttime.sleep(2*max(1,len(x) * 0.01))\n",
        "\t\tposts = [p for p in posts if bool(p['excerpt']) and bool(p['title'])]\n",
        "\t\trandom.shuffle(posts)\n",
        "\t\tcache['posts'] = posts\n",
        "\tdef take_post():\n",
        "\t\telem = posts[randint(0,len(posts)-1)] \n",
        "\t\tposts.remove(elem)\n",
        "\t\treturn elem\n",
        "\tgptWebsite = cache.get('ChatGPTWebsite',ChatGPTWebsite(driver,skip=False))\n",
        "\t\n",
        "\ttime.sleep(7)\n",
        "\t\n",
        "\tencodedChatLog: List[str] = []\n",
        "\tcache['encodedChatLog'] = encodedChatLog\n",
        "\tchatLog: List[Message] = []\n",
        "\tcache['chatLog'] = chatLog\n",
        "\tpromptLog: List[str] = []\n",
        "\tcache['promptLog'] = promptLog\n",
        "\tdataLog: List[str] = []\n",
        "\tcache['dataLog'] = dataLog\n",
        "\ttell(cache,'.')\n",
        "\t\n",
        "\tencoder = Encoder(data,dataLog,encodedChatLog,identity)\n",
        "\n",
        "\tcache['aliceChat'] = gptWebsite.getLandingNewChat()\n",
        "\taliceChat = cache['aliceChat'] \n",
        "\n",
        "\t# alice first message\n",
        "\tpromptLog.append(prompts.start_conversation_with_post(alice,bob,take_post()))\n",
        "\ttell(cache,'.')\n",
        "\tchatLog.append(Message(alice,aliceChat.ask(promptLog[-1])))\n",
        "\ttell(cache,'.')\n",
        "\tencoder(chatLog[-1].text)\n",
        "\ttell(cache,'.')\n",
        "\n",
        "\t# bob first message\n",
        "\tpromptLog.append(prompts.receiverStartChatReplyPrompt(Message(person=alice,text=encodedChatLog[-1])))\n",
        "\ttell(cache,'.')\n",
        "\ta,bobChat = aliceChat.askNew(promptLog[-1])\n",
        "\ttell(cache,'.')\n",
        "\tchatLog.append(Message(bob,a))\n",
        "\ttell(cache,'.')\n",
        "\n",
        "\t# alice second message\n",
        "\tpromptLog.append(prompts.senderStartChatReplyPrompt(chatLog[-1]))\n",
        "\ttell(cache,'.')\n",
        "\tchatLog.append(Message(alice, aliceChat.ask(promptLog[-1])))\n",
        "\ttell(cache,'.')\n",
        "\ta = encoder(chatLog[-1].text)\n",
        "\ttell(cache,'.')\n",
        "\talice_message_number = 2\n",
        "\n",
        "\twhile True:\n",
        "\t\tif encoder.done():\n",
        "\t\t\tpromptLog.append(prompts.endChatReplyPrompt(chatLog[-1]))\n",
        "\t\t\ttell(cache,'.')\n",
        "\t\t\tchatLog.append(Message(alice, aliceChat.ask(promptLog[-1])))\n",
        "\t\t\ttell(cache,'.')\n",
        "\t\t\ta = encoder(chatLog[-1].text)\n",
        "\t\t\ttell(cache,'.')\n",
        "\t\t\treturn None\n",
        "\n",
        "\t\tpromptLog.append(prompts.receiverInChatReplyPrompt(Message(alice,encodedChatLog[-1])))\n",
        "\t\ttell(cache,'.')\n",
        "\t\tchatLog.append(Message(bob, bobChat.ask(promptLog[-1])))\n",
        "\t\ttell(cache,'.')\n",
        "\t\t\n",
        "\t\t# switch\n",
        "\t\talice_message_number += 1\n",
        "\t\tpromptLog.append(prompts.senderInChatReplyPrompt(chatLog[-1],take_post() if alice_message_number % 7 == 0 else None))\n",
        "\t\ttell(cache,'.')\n",
        "\t\tchatLog.append(Message(alice, aliceChat.ask(promptLog[-1])))\n",
        "\t\ttell(cache,'.')\n",
        "\t\ta = encoder(chatLog[-1].text)\n",
        "\t\ttell(cache,'.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# run it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "openChannelAndSend(data,subreddit='CasualConversation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "tell(cache,'.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nasoo\\Desktop\\Y5Project\\Port\\benchmarks_spans_5\\2023-08-13 13-11-14\\cache.json.html\n",
            "Opened c:\\Users\\nasoo\\Desktop\\Y5Project\\Port\\benchmarks_spans_5\\2023-08-13 13-11-14\\cache.json.html in the default application.\n"
          ]
        }
      ],
      "source": [
        "from json import dumps\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import json\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "def augment_stats():\n",
        "  df = pd.read_csv('./stats.tsv',delimiter='\\t')\n",
        "  df['capacity'] = df['capacity'].apply(lambda x : round(100*x) if isinstance(x,float) else x)\n",
        "  df.to_csv('./stats.tsv',sep='\\t',index=False)\n",
        "  dfd = df.describe()\n",
        "  dfd['bits'] = dfd['bits'].apply(lambda a: int(round(a)))\n",
        "  dfd['cover size'] = dfd['cover size'].apply(lambda a: int(round(a)))\n",
        "  dfd['capacity'] = dfd['capacity'].apply(lambda a: int(round(a)))\n",
        "  dfd.to_csv('./stats.stats.tsv',sep='\\t')\n",
        "\n",
        "def render(path,image=None):\n",
        "  with open(path,'r') as fff:\n",
        "    cache = json.loads(fff.read())\n",
        "  stats_path = path[:-len('cache.json')]+'stats.tsv'\n",
        "  stats = pd.read_csv(stats_path,delimiter='\\t')\n",
        "  stats_stats = pd.read_csv(path[:-len('cache.json')]+'stats.stats.tsv',delimiter='\\t')\n",
        "  stats_stats.rename(columns={'Unnamed: 0':''},inplace=True)\n",
        "  normal_chat = json.dumps(cache['chatLog'])\n",
        "  encoded_chat = []\n",
        "  aliceChatLog: List[str] = cache['encodedChatLog']\n",
        "  def f(i,m):\n",
        "    if len(aliceChatLog) > 0:\n",
        "      m['text'] = aliceChatLog[0]\n",
        "      aliceChatLog.remove(m['text'])\n",
        "    return m\n",
        "  aliceChatLog = list(f(i,m) for i, m in enumerate(cache['chatLog']) if m['person'] == 'alice nice')\n",
        "  bobChatLog = list(m for m in cache['chatLog'] if m['person'] == 'bob wick')\n",
        "  for i in range(max(len(aliceChatLog),len(bobChatLog))):\n",
        "    if i < len(aliceChatLog):\n",
        "      encoded_chat.append(aliceChatLog[i])\n",
        "    if i < len(bobChatLog):\n",
        "      encoded_chat.append(bobChatLog[i])\n",
        "  encoded_chat = json.dumps(encoded_chat)\n",
        "  encoded_chat_data = json.dumps([{'bits':x[0],'cover size':x[1],'capacity':f'{x[2]}%'} for x in stats.to_numpy().tolist()])\n",
        "  summary = stats_stats.to_html(index=False)\n",
        "  image_details = '' \n",
        "  if not image is None:\n",
        "    with open(image+'.html','r') as ff:\n",
        "      image_details = ff.read()\n",
        "    print(image_details)\n",
        "  image = '' if image is None else f'<img src=\"file://{os.path.abspath(image)}\" style=\"width: fit-content;height: fit-content;scale: 25;margin: 7rem;\"/>'\n",
        "  with open('./chat.template.html','r') as fff, open(f'{path}.html','w') as o:\n",
        "    o.write(fff.read().replace('$normal_chat',normal_chat)\n",
        "    .replace('$encoded_chat_data',encoded_chat_data)\n",
        "    .replace('$encoded_chat',encoded_chat)\n",
        "    .replace('$summary',summary)\n",
        "    .replace('$image_details',image_details)\n",
        "    .replace('$image',image)\n",
        "    )\n",
        "  file_path = os.path.abspath(f'{path}.html'.replace('/','\\\\'))\n",
        "  print(file_path)\n",
        "  try:\n",
        "      subprocess.Popen(['start', '', file_path], shell=True)\n",
        "      print(f\"Opened {file_path} in the default application.\")\n",
        "  except Exception as e:\n",
        "      print(f\"Error: {e}\")\n",
        "\n",
        "def saveCache(cache=cache):\n",
        "  id = datetime.now().__str__().replace(':','-')[:19]\n",
        "  tell(cache,'.')\n",
        "  dir_path = f'benchmarks_spans_5/{id}'\n",
        "  os.mkdir(dir_path)\n",
        "\n",
        "  augment_stats()\n",
        "  shutil.move('stats.tsv', dir_path+'/stats.tsv')\n",
        "  shutil.move('cache.json', dir_path+'/cache.json')\n",
        "  shutil.move('stats.stats.tsv', dir_path+'/stats.stats.tsv')\n",
        "  shutil.move('steps.log', dir_path+'/steps.log')\n",
        "  shutil.move('pie.tsv', dir_path+'/pie.tsv')\n",
        "  render(f'{dir_path}/cache.json')\n",
        "\n",
        "saveCache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nasoo\\Desktop\\Y5Project\\Port\\benchmarks_spans_5\\2023-08-13 12-43-09\\cache.json.html\n",
            "Opened c:\\Users\\nasoo\\Desktop\\Y5Project\\Port\\benchmarks_spans_5\\2023-08-13 12-43-09\\cache.json.html in the default application.\n"
          ]
        }
      ],
      "source": [
        "render('benchmarks_spans_5/2023-08-13 12-43-09/cache.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# df = pd.read_csv('./examples/ZcEybAIIxHKeeuiqUapd/pie.tsv',delimiter='\\t')\n",
        "fs = ['12-43-09','13-11-14']\n",
        "for f in fs:\n",
        "\tdf = pd.read_csv(f'./benchmarks_spans_5/2023-08-13 {f}/pie.tsv',delimiter='\\t')\n",
        "\tdf['MLM capacity'] = df['MLM capacity'].apply(lambda x : round(100*x) if isinstance(x,float) else x)\n",
        "\tdf['Typo capacity'] = df['Typo capacity'].apply(lambda x : round(100*x) if isinstance(x,float) else x)\n",
        "\tdf['Emo capacity'] = df['Emo capacity'].apply(lambda x : round(100*x) if isinstance(x,float) else x)\n",
        "\tdf.columns = df.columns.astype(str)\n",
        "\ttypo = df[['cover size', 'Typo bits','Typo capacity']]\n",
        "\ttypo = typo.rename({ \n",
        "\t\t'cover size': \"cover size\"\n",
        "\t\t,'Typo bits': \"bits\"\n",
        "\t\t,'Typo capacity': \"ratio\"\n",
        "\t})\n",
        "\temo = df[['cover size', 'Emo bits','Emo capacity']]\n",
        "\temo = emo.rename({ \n",
        "\t\t'cover size': \"cover size\"\n",
        "\t\t,'Emo bits': \"bits\"\n",
        "\t\t,'Emo capacity': \"ratio\"\n",
        "\t})\n",
        "\ttypo.to_csv(f'./d typo benchmark{f}.tsv',sep='\\t',index=False)\n",
        "\temo.to_csv(f'./d emoji benchmark{f}.tsv',sep='\\t',index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
