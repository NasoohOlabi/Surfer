{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys\n",
        "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '../'))\n",
        "if parent_dir not in sys.path:\n",
        "    sys.path.insert(0, parent_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from itertools import islice\n",
        "import time\n",
        "from random import randint\n",
        "import random\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from Surfer import GetBrowser,RedditFeed,Feed,ChatGPT,ChatGPTWebsite\n",
        "from Surfer.ScriptRunner import ScriptRunner\n",
        "from files import *\n",
        "from Stegasus import stegasus\n",
        "from Bot import *\n",
        "from Chatter import prompts\n",
        "from Surfer.util import uuid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'10001001010100000100111001000111000011010000101000011010000010100000000000000000000000000000110101001001010010000100010001010010000000000000000000000000000001110000000000000000000000000000011100001000000001100000000000000000000000001100010001010010010101111101001100000000000000000000000000001001011100000100100001011001011100110000000000000000000000111101100000000000000000000000001111011000000000010110111001000111011000110011010100000000000000000000000011010110010010010100010001000001010101000000100001011011000000011100101100000000001101001111111100000001101010111010100110101101111111111111110011111000111011010000000011110110110011011101001100000000111010011101010111100000000000000000011100101101001010010000000000010100001100010010101100000000111111111111111111111111000000000000000110110011101101101011011011111111111111101110110011101100000000001110011010111000110001010000000000001000000000010000101000000000111110010010010100011000000000000000100100100001000110000000000011111111111111111111111100000000000000011001111110100011101000011111111100010001111111010000001100000000111001111011110111001110000000000000001100000101000010000000000000001111001101110010100100000000111101110000011111111101000000000000000100000001000000010000000000000001101000001001111110011111111111111111010111110011111101000000000011110110110110011110010100000000000001010000010100000110000000001101110011110101111010110000000000011111001001100010001000000000000100110001001100010011000000000000000101110101011100100111001111111111110011111101010011010010000000000010111000100101001010000000000000000011000000010000001000000000101110011100001010111110000000000001010000000110000011000000000000110101010001100100000000000000000000010110011001100110011001101111111111011011110110111101101100000000000111010001110100011101000000001110110111101101111011010000000011011101110110111101110000000000010010100010110000110110000000000001000100110011001001110000000000000001011010100110101001101010111111111100010111000101110001010000000000010111000101110001011100000000000001000000010000000100000000001101110011010110110110000000000001010001001011100011101000000000111010110001000000000011000000000000100110000101010011011001001110000100100101111010011111011010000000000000000000000000000000000100100101000101010011100100010010101110010000100110000010000010'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example usage\n",
        "ex = \"png\"\n",
        "file_path = f'micro_rick_roll.{ex}'\n",
        "data = ''\n",
        "for chunk in read_file_in_chunks(file_path):\n",
        "    data += chunk\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2336\n",
            "1024\n"
          ]
        }
      ],
      "source": [
        "# KB\n",
        "print(len(data))\n",
        "data = data[:2**10]\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "cache = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Encoder:\n",
        "\tdef __init__(self,data,dataLog,encodedChatLog,identity=False):\n",
        "\t\tself.data = data\n",
        "\t\tself.rem = data\n",
        "\t\tself.dataLog = dataLog\n",
        "\t\tself.encodedChatLog = encodedChatLog\n",
        "\t\tself.dataLog.append('')\n",
        "\t\tself.sending_pure_padding = False\n",
        "\t\tself.identity = identity\n",
        "\t\tself.size = 0\n",
        "\n",
        "\tdef done(self):\n",
        "\t\tself.size += 1\n",
        "\t\treturn self.sending_pure_padding if not self.identity else self.size <= 10\n",
        "\n",
        "\tdef __call__(self,text) -> str:\n",
        "\t\tif self.identity:\n",
        "\t\t\treturn text\n",
        "\t\t# sending pure padding\n",
        "\t\tself.sending_pure_padding = len(self.rem) < 499\n",
        "\t\ta, self.rem = stegasus.StegasusEncode(text,self.rem)\n",
        "\t\tself.encodedChatLog.append(a)\n",
        "\t\tself.dataLog.append(data[len(self.dataLog[-1]):-len(self.rem)])\n",
        "\t\treturn a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import importlib\n",
        "# importlib.reload(prompts)\n",
        "\n",
        "# backup_post = [p for p in cache['posts'] if not (p['title'] is not None and p['title'] != \"\" and p['excerpt'] is not None and p['excerpt'] != \"\")][0]\n",
        "# a = prompts.inChatReplyPrompt(Message(Person('alice','nice',23,'female','Boston','alice@gmail.com'),'sup dog'),backup_post)\n",
        "# print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['data', 'driver', 'RedditFeed', 'posts', 'ChatGPTWebsite', 'encodedChatLog', 'chatLog', 'promptLog', 'dataLog', 'aliceChat', 'bobChat']\n",
            "['data', 'driver', 'RedditFeed', 'posts', 'ChatGPTWebsite', 'encodedChatLog', 'chatLog', 'promptLog', 'dataLog', 'aliceChat', 'bobChat']\n"
          ]
        }
      ],
      "source": [
        "print(list(cache.keys()))\n",
        "# del cache['data']\n",
        "# del cache['driver']\n",
        "# del cache['RedditFeed']\n",
        "# del cache['posts']\n",
        "# del cache['ChatGPTWebsite']\n",
        "# del cache['encodedChatLog']\n",
        "# del cache['chatLog']\n",
        "# del cache['promptLog']\n",
        "# del cache['dataLog']\n",
        "# del cache['aliceChat']\n",
        "# del cache['bobChat']'\n",
        "print(list(cache.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "def openChannelAndSend(data:str\n",
        ", alice = Person('alice','nice',23,'female','Boston','alice@gmail.com')\n",
        ", bob = Person('bob','wick',29,'male','Boston','bob@gmail.com')):\n",
        "\tdata += '1' + ('0' * 500)\n",
        "\tcache['data'] = data\n",
        "\tif 'driver' in cache:\n",
        "\t\tdriver = cache['driver']\n",
        "\telse:\n",
        "\t\tcache['driver'] = GetBrowser()\n",
        "\t\tdriver = cache['driver']\n",
        "\tdriver.implicitly_wait(2)\n",
        "\tcache['RedditFeed']= cache.get('RedditFeed',RedditFeed(driver,skip=False,subreddit='unpopularopinion',newWindow=False))\n",
        "\trf = cache['RedditFeed'] \n",
        "\t# rf = RedditFeed(driver,skip=True)\n",
        "\tposts = []\n",
        "\tif 'posts' in cache:\n",
        "\t\tposts = cache['posts']\n",
        "\telse:\n",
        "\t\tfor x in islice(rf,15):\n",
        "\t\t\tposts.append(x)\n",
        "\t\t\ttime.sleep(2*max(1,len(x) * 0.01))\n",
        "\t\tposts = [p for p in posts if bool(p['excerpt']) and bool(p['title'])]\n",
        "\t\trandom.shuffle(posts)\n",
        "\t\tcache['posts'] = posts\n",
        "\t\t\n",
        "\tcache['ChatGPTWebsite'] = cache.get('ChatGPTWebsite',ChatGPTWebsite(driver,skip=False))\n",
        "\tgptWebsite = cache['ChatGPTWebsite'] \n",
        "\t\n",
        "\ttime.sleep(7)\n",
        "\t\n",
        "\tencodedChatLog: List[str] = []\n",
        "\tcache['encodedChatLog'] = encodedChatLog\n",
        "\tchatLog: List[Message] = []\n",
        "\tcache['chatLog'] = chatLog\n",
        "\tpromptLog: List[str] = []\n",
        "\tcache['promptLog'] = promptLog\n",
        "\tdataLog: List[str] = []\n",
        "\tcache['dataLog'] = dataLog\n",
        "\t\n",
        "\tencoder = Encoder(data,dataLog,encodedChatLog,True)\n",
        "\n",
        "\tcache['aliceChat'] = cache.get('aliceChat', gptWebsite.getLandingNewChat())\n",
        "\taliceChat = cache['aliceChat'] \n",
        "\tif len(promptLog) == 0:\n",
        "\t\t# promptLog 0\n",
        "\t\tpromptLog.append(prompts.start_conversation_with_post(alice,bob,posts[randint(0,len(posts)-1)]))\n",
        "\t\n",
        "\tif len(chatLog) == 0:\n",
        "\t\t# chatLog 0\n",
        "\t\tchatLog.append(Message(alice,aliceChat.ask(promptLog[0])))\n",
        "\t\n",
        "\tencoder(chatLog[0].text)\n",
        "\n",
        "\tif 'bobChat' not in cache or len(chatLog) == 1 or len(promptLog) == 1:\n",
        "\t\t# promptLog 1\n",
        "\t\tpromptLog.append(prompts.startChatReplyPrompt(chatLog[0]))\n",
        "\t\ta,bobChat = aliceChat.askNew(promptLog[1])\n",
        "\t\t# chatLog 1\n",
        "\t\tchatLog.append(Message(bob,a))\n",
        "\t\tcache['bobChat'] = bobChat\n",
        "\telse:\n",
        "\t\tbobChat =cache['bobChat']\n",
        "\n",
        "\t# chatLog 2\n",
        "\tchatLog.append(Message(alice, aliceChat.ask(prompts.startChatReplyPrompt(chatLog[1]))))\n",
        "\ta = encoder(chatLog[2].text)\n",
        "\t\n",
        "\tcIdx = 2\n",
        "\twhile True:\n",
        "\t\tif encoder.done():\n",
        "\t\t\t# chatLog cIdx+1\n",
        "\t\t\tchatLog.append(Message(alice, aliceChat.ask(prompts.endChatReplyPrompt(chatLog[cIdx]))))\n",
        "\t\t\tcIdx += 1\n",
        "\t\t\ta = encoder(chatLog[cIdx].text)\n",
        "\t\t\treturn None\n",
        "\n",
        "\t\t# chatLog cIdx+1\n",
        "\t\tchatLog.append(Message(bob, bobChat.ask(prompts.inChatReplyPrompt(chatLog[cIdx],posts[randint(0,len(posts)-1)]))))\n",
        "\t\tcIdx += 1\n",
        "\t\t\n",
        "\t\t# switch\n",
        "\t\t\n",
        "\t\t# chatLog cIdx+1\n",
        "\t\tchatLog.append(Message(alice, aliceChat.ask(prompts.inChatReplyPrompt(chatLog[cIdx],posts[randint(0,len(posts)-1)]))))\n",
        "\t\tcIdx += 1\n",
        "\t\ta = encoder(chatLog[cIdx].text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'datetime.datetime' object has no attribute 'sleep'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[98], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m openChannelAndSend(data)\n",
            "Cell \u001b[1;32mIn[97], line 21\u001b[0m, in \u001b[0;36mopenChannelAndSend\u001b[1;34m(data, alice, bob)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m islice(rf,\u001b[39m15\u001b[39m):\n\u001b[0;32m     20\u001b[0m \tposts\u001b[39m.\u001b[39mappend(x)\n\u001b[1;32m---> 21\u001b[0m \ttime\u001b[39m.\u001b[39;49msleep(\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39mmax\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39mlen\u001b[39m(x) \u001b[39m*\u001b[39m \u001b[39m0.01\u001b[39m))\n\u001b[0;32m     22\u001b[0m posts \u001b[39m=\u001b[39m [p \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m posts \u001b[39mif\u001b[39;00m \u001b[39mbool\u001b[39m(p[\u001b[39m'\u001b[39m\u001b[39mexcerpt\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mand\u001b[39;00m \u001b[39mbool\u001b[39m(p[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m])]\n\u001b[0;32m     23\u001b[0m random\u001b[39m.\u001b[39mshuffle(posts)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'datetime.datetime' object has no attribute 'sleep'"
          ]
        }
      ],
      "source": [
        "openChannelAndSend(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from json import dumps\n",
        "from json import JSONEncoder\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import json\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "def render(path):\n",
        "  with open(path,'r') as f:\n",
        "    cache = json.loads(f.read())\n",
        "  normal_chat = json.dumps(cache['chatLog'])\n",
        "  encoded_chat = []\n",
        "  aliceChatLog: List[str] = cache['encodedChatLog']\n",
        "  def f(i,m):\n",
        "    m['text'] = aliceChatLog[0]\n",
        "    aliceChatLog.remove(m['text'])\n",
        "    return m\n",
        "  aliceChatLog = list(f(i,m) for i, m in enumerate(cache['chatLog']) if m['person'] == 'alice nice')\n",
        "  bobChatLog = list(m for m in cache['chatLog'] if m['person'] == 'bob wick')\n",
        "  for i in range(max(len(aliceChatLog),len(bobChatLog))):\n",
        "    if i < len(aliceChatLog):\n",
        "      encoded_chat.append(aliceChatLog[i])\n",
        "    if i < len(bobChatLog):\n",
        "      encoded_chat.append(bobChatLog[i])\n",
        "  encoded_chat = json.dumps(encoded_chat)\n",
        "  with open('./chat.template.html','r') as f, open(f'{path}.html','w') as o:\n",
        "    o.write(f.read().replace('$normal_chat',normal_chat)\n",
        "    .replace('$encoded_chat',encoded_chat))\n",
        "  file_path = os.path.abspath(f'{path}.html'.replace('/','\\\\'))\n",
        "  print(file_path)\n",
        "  try:\n",
        "      subprocess.Popen(['start', '', file_path], shell=True)\n",
        "      print(f\"Opened {file_path} in the default application.\")\n",
        "  except Exception as e:\n",
        "      print(f\"Error: {e}\")\n",
        "def augment_stats():\n",
        "  df = pd.read_csv('./stats.tsv',delimiter='\\t')\n",
        "  df['capacity'] = df['capacity'].apply(lambda x : round(100*x) if isinstance(x,float) else x)\n",
        "  df.to_csv('./stats.tsv',sep='\\t',index=False)\n",
        "  dfd = df.describe()\n",
        "  dfd['bits'] = dfd['bits'].apply(lambda a: int(round(a)))\n",
        "  dfd['cover size'] = dfd['cover size'].apply(lambda a: int(round(a)))\n",
        "  dfd['capacity'] = dfd['capacity'].apply(lambda a: int(round(a)))\n",
        "  dfd.to_csv('./stats.stats.tsv',sep='\\t')\n",
        "\n",
        "class MessageEncoder(JSONEncoder):\n",
        "  def default(self, obj):\n",
        "    if isinstance(obj, Message):\n",
        "      return {\n",
        "        'person': f\"{obj.person.first_name} {obj.person.last_name}\",\n",
        "        'text': obj.text,\n",
        "        'time': obj.time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "      }\n",
        "    return super().default(obj)\n",
        "\n",
        "def saveCache(cache=cache):\n",
        "  id = uuid()\n",
        "  dir_path = f'examples/{id}'\n",
        "  os.mkdir(dir_path)\n",
        "\n",
        "  with open(f'{dir_path}/cache.json','w') as f:\n",
        "    f.write(dumps({\n",
        "      'chatLog':cache['chatLog']\n",
        "      , 'encodedChatLog': cache['encodedChatLog']\n",
        "      , 'promptLog': cache['promptLog']\n",
        "      , 'dataLog': cache['dataLog']\n",
        "      , 'data': cache['data']\n",
        "      },cls=MessageEncoder))\n",
        "  augment_stats()\n",
        "  shutil.move('stats.tsv', dir_path+'/stats.tsv')\n",
        "  shutil.move('stats.stats.tsv', dir_path+'/stats.stats.tsv')\n",
        "  shutil.move('step.log', dir_path+'/step.log')\n",
        "  shutil.move('pie.log', dir_path+'/pie.log')\n",
        "  render(f'{dir_path}/cache.json')\n",
        "\n",
        "saveCache()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
